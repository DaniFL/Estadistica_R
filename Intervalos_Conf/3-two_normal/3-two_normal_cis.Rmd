---
title: "Intervalos de confianza y test de hipótesis para dos poblaciones normales"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Comparaciones de medias en poblaciones normales
## Varianzas totalmente desconocidas

### Diferencias por sexos
Los datos contenidos en "howell1.csv" son datos censales parciales del
área !Kung San compilados a partir de entrevistas realizadas a finales de la década
de 1960. ¿Depende la altura de los !Kung adultos del sexo del inviduo? ($\alpha=0.01$). 

Apoya tus resultados con un gráfico y calcula el tamaño del efecto. Emplea 
los datos en "howell1.csv".

```{r}
library(readr)
howell1 = read_delim("Intervalos_Conf/3-two_normal/data_3/howell1.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)

# Método 1
data = howell1[howell1$age >= 18, ]
data$male = factor(data$male)
View(data)

# Método 2 (dplyr)
library(tydyverse)
data2 = filter(howell1, age >= 18) 
data2 = mutate(data2, male = factor(male)) 
View(data2)

# 1) Formular hipótesis
# X: altura de los !Kung adultos
# H0: mu_hombres = mu_mujeres
# H1: mu_hombres != mu_mujeres

library(ggplot2)
ggplot(data, aes(x = height, y = weight, col = male)) + 
  #geom_line() +
  geom_point() +
  geom_smooth() 


ggplot(data, aes(x = height, fill = male, col = male)) + 
  #geom_histogram()
  geom_density(alpha = 0.5)
  
# 2) Comprobar asunciones
# 2.1) Normalidad -> histograma
hist(data$height, col = "lightblue")
# 2.2) Independencia: a) Muestra aleatoria b) Poblacion muy grande comparado con la muestra
# Asumo que el tamaño de la muestra es menor al 10% del tamaño de la poblacion

# 3) Elegir estadístico de contraste 
# media muestral hombres
# media muestral mujeres 
# T = media muestral hombres - media muestral mujeres (t-student)
# T >> 0 --> hombres > mujeres
# T << 0 --> hombres < mujeres
# T ~ 0 --> hombres = mujeres

# Ha = mu_hombres - mu_mujeres != 0
hombres = data[data$male == 1, ]
mujeres = data[data$male == 0, ]

# Discutir disribucion de T-student con dos poblaciones (hombres y mujeres)

# 1) Normalidad poblaciones (por separado) -> razonable en base al gráfico
# 2) Independencia -> razonable en base a la forma de obtención de los datos
# 2.1) Independencia poblaciones
# 2.2) Independencia de las muestras dentro de cada poblacion

# Debido a que padres altos tienden a tener hijos altos y madres altas tienden a tener hijas altas
# la independencia de las muestras dentro de cada poblacion no se cumple (2.1/2.2)
# Si la población es muy grande y la muestra es pequeña en comparación, la asunción de independencia si es razonable ppor que será dificil que miembros de una misma familia estén en la muestra.
t_test = t.test(hombres$height, mujeres$height, alternative = "two.sided", conf.level = 0.99, mu = 0)

library("effectsize")
cohens_d = effectsize(t_test)
print(cohens_d)

# Conclusiones
# La estatura de los hombres es mayor que la de las mujeres
# Los hombres miden 10.85 cm más de media que las mujeres
# El tamaño del efecto es grande (1.69 - 2.29)
```


## Varianzas desconocidas pero iguales
### Varianzas desconocidas pero iguales
Repite el ejercicio relativo a los !Kung adultos si se puede asumir que 
la desviación típica poblacional para hombres y mujeres es la misma 
($\sigma_h = \sigma_m$).

```{r}
t_test = t.test(hombres$height, mujeres$height, alternative = "two.sided", conf.level = 0.99, mu = 0, var.equal = TRUE)

library("effectsize")
cohens_d = effectsize(t_test)
print(cohens_d)
```


## Datos apareados
### Datos apareados
Unos científicos examinaron la función de la vesícula biliar antes y 
después de una cirugía  para detener el reflujo. Los autores midieron 
la funcionalidad de la vesícula biliar calculando la fracción de eyección de
la vesícula biliar (GBEF) antes y después de la operación. El objetivo de la 
operación es aumentar la GBEF. ¿Hay evidencia para concluir que la operación 
aumenta el GBEF? Datos en "gbef\_long.txt" (o "gbef.txt", para un reto).

```{r}
library(readr)
gbef_long <- read_table("Intervalos_Conf/3-two_normal/data_3/gbef_long.csv")
View(gbef_long)

gbref_long$ID = factor(gbref_longs$ID)
gbref_long$class = factor(gbref_longs$class)

library(dplyr)
gbref_long =mutate(gbref_long, ID = factor(ID))

# 2) 
# X: valor de GBEF
# H0: mu_post <= mu_pre -> mu_post = mu_pre
# Ha: mu_post > mu_pre
```
$$Ha: \mu_{post} > \mu_{pre} -> \mu_{post} - \mu_{pre} > 0$$
```{r}
# 3) Elección estadístico de contraste
# T = media muestral post - media muestral pre
```
$$T = \bar{X}_{post} - \bar{X}_{pre}$$
```{r}
# Independencia: entre post y pre hay dependencia por que se tratan de datos apareados
# Para cada persona estudiamos el valor de GBEF antes y después de la operación

# Normalidad:
pre = gbef_long[gbef_long$class == "Preop", ]
post = gbef_long[gbef_long$class == "Postop", ]

D = post$gbef - pre$gbef
hist(D, col = "lightblue")

# 3) 
# Ha: mu_post > mu_pre -> mu_post - mu_pre > 0
t.test(D, alternative = "greater", mu = 0)
# Ha: mupost > mu pre
t_test = t.test(post$gbef, pre$gbef, alternative = "greater", mu = 0, paired = TRUE)

cohens_d = effectsize(t_test)

# 4) interpretar soluciones
# No hay evidencia concluyente de que la operación funciones p-value = 0.04086, sin embargo parace prometedora ya que la ganancia de gbef media es de 18.075. Además este efecto puede tener relevancia pratica ya que corresponde con un tamaño de efecto medio (0.5), aunque 95% IC (o.03-Inf)

# Recomendamos hacer un estudio con mas muestras 
# haz un power t.test paara averiguar e numero muestras
# que necesitamos para detectar un efecto de 18.075 con un poder del 80%
# y un nivel de significación del 5%
power.t.test(delta = 18.075, sd = sd(D), sig.level = 0.01, power = 0.9, type = "paired", alternative = "one.sided")
```
# Comparaciones de varianzas

### Comparaciones de varianzas
En una empresa, se están comparando dos métodos de producción de cierto chip 
(A, mucho más barato, y B). La potencia media consumida por ambos chips es 
idéntica, si bien los dos métodos tienen distinta variabilidad. Se obtienen 
dos muestras de tamaño 16 y 10 y sus varianzas muestrales son
$24$ y $18$ (en Watts$^2$). Usando un nivel de confianza del 98\%, ¿qué método 
es preferible? Usa la función *var.test*.

```{r}

# 1)
# X: varianza muestral de A y B
# H0:  sigma_A^2 / sigma_B^2 = 1
# Ha:  sigma_A^2 / sigma_B^2 > 1

# P-valor
p_value = 1 - pf(1.33, 15, 9)

# Intervalo confianza
1/qf(1-0.02/2, 15, 9) * 24/18
1/qf(0.02/2, 15, 9) * 24/18

# Conclusiones
# No hay evidencia concluyente de que las varianzas sean distintas
# No podemos rechazar la hipotesis nula

# Estos no sirven
datos_a = rnorm(16, 0, sqrt(24))
datos_b = rnorm(10, 0, sqrt(18))

# Estandarización datos ==>  media = 0, desviación tipica de 1
datos_a = rnorm(16)
datos_a = (datos_a - mean(datos_a)) / sd(datos_a)
datos_a = datos_a * sqrt(24) + 3

datos_b = rnorm(10)
datos_b = (datos_b - mean(datos_b)) / sd(datos_b)
datos_b = datos_b * sqrt(18) + 3

var.test(datos_a, datos_b, ratio = 1, alternative = "two.sided", conf.level = 0.98)

# Ha: var_b > 2 * var_a --> var_b / var_a > 2
# Ha:var_a / var_b < 0.5
var.test(datos_b, datos_a, ratio = 2, alternative = "greater", conf.level = 0.98)
```

--- 

Resuelve el mismo ejercicio empleando haciendo los cálculos del IC y del 
p-valor "a mano".

```{r}
# ??
```


### !Kung y varianzas
Usa un test de ratio de varianzas para discutir si es razonable asumir 
igualdad de varianzas en el ejercicio de los !Kung (¿Existe evidencia de que 
las varianzas por sexo son distintas?)

```{r}
# ??
```

